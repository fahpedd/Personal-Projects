{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Set some parameters to get good visuals - style to ggplot and size to 15,10\n",
    "pd.set_option('display.precision',4)\n",
    "\n",
    "pd.set_option('display.width',170, 'display.max_rows',200, 'display.max_columns',900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset has been created using the tables from:\n",
    "\n",
    "###### Data Columns for 2011 are listed below, same number of columns for 2016 \n",
    "* 2011_Mortgate_Count\t\n",
    "* 2011_New_House_Price\t\n",
    "* 2011_Second_Hand_Price\t\n",
    "* 2011_Sum_of_Price\t\n",
    "* 2011_Male_Population\t\n",
    "* 2011_Female_Population\t\n",
    "* 2011_Total_Population\t\n",
    "* 2011_Migration_Population\t\n",
    "* 2011_LA_Arrears\t\n",
    "* 2011_1 - 14 years\t\n",
    "* 2011_15 - 19 years\t\n",
    "* 2011_20 - 24 years\t\n",
    "* 2011_25 - 29 years\t\n",
    "* 2011_30 - 34 years\t\n",
    "* 2011_35 - 44 years\t\n",
    "* 2011_45 - 54 years\t\n",
    "* 2011_55 - 64 years\t\n",
    "* 2011_65 - 74 years\t\n",
    "* 2011_75 years and over\t\n",
    "* 2011_employment\t\n",
    "* 2011_Married_First_Marriage\t\n",
    "* 2011_Divorsed\n",
    "* 2011_AVG_Interest_Rate\n",
    "\n",
    "\n",
    "* National average mortgage interest rates (from 2011 - 2017) -- we need to calculate the difference every year\n",
    "* Sum of House Prices (2011 -2017) -- we need to calculate the difference every year\n",
    "* Mortgage Arrears by county (2011 -2017): This is important to make the arrears prediction\n",
    "* Loan Paid by an individual for both new and second-hand property (2011-2017)\n",
    "* Population by gender (2011 and 2016 )\n",
    "* Repossessions (2011 and 2016 )\n",
    "* Loans approved (2011 and 2016 )\n",
    "* Principal economic status of the population living in the counties\n",
    "* Commuter details\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Data Preparation Notes:\n",
    "* Property register data cleaning\n",
    "* Using MID function in excel extracted date for pivot table to filter out data for each year. \n",
    "* Teach/Árasán Cónaithe Atháimhe \n",
    "###### UPDATED TO \n",
    "* Second-Hand Dwelling house /Apartment\n",
    "\n",
    "* Teach/Árasán Cónaithe Nua\n",
    "* Teach/?ras?n C?naithe Nua\n",
    "###### UPDATED TO \n",
    "* New Dwelling house /Apartment\n",
    "\n",
    "* Male female population:\n",
    "* County data was not in alphabetical order when downloaded so it has to be sorted ascending order before the data is copied over.\n",
    "\n",
    "* Migration data/Arrears Data/Marital Status data\n",
    "\n",
    "##### City\n",
    "* Cork City and Cork County details are merged for CORK count \n",
    "###### Below listed are merged for DUBLIN count\n",
    "    * Dublin City\n",
    "    * Dún Laoghaire-Rathdown\n",
    "    * Fingal\n",
    "    * South Dublin\n",
    "\n",
    "###### Below listed are merged for GALWAY count\n",
    "    * Galway City\n",
    "    * Galway County\n",
    "\n",
    "\n",
    "###### INTEREST RATE\n",
    "* Average calculated from 12 months. \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mortgage_arrears.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print (\"\\n\\n---------------------\")\n",
    "# print (\"DATA SET INFORMATION\")\n",
    "# print (\"---------------------\")\n",
    "# print (\"Shape of training set:\", df.shape, \"\\n\")\n",
    "# print (\"Column Headers:\", list(df.columns.values), \"\\n\")\n",
    "# print (df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# missing_values = []\n",
    "# nonumeric_values = []\n",
    "\n",
    "# print (\"DATA SET INFORMATION\")\n",
    "# print (\"========================\\n\")\n",
    "\n",
    "# for column in df:\n",
    "#     # Find all the unique feature values\n",
    "#     uniq = df[column].unique()\n",
    "#     print (\"'{}' has {} unique values\" .format(column,uniq.size))\n",
    "#     if (uniq.size > 10):\n",
    "#         print(\"~~Listing up to 10 unique values~~\")\n",
    "#     print (uniq[0:10])\n",
    "#     print (\"\\n-----------------------------------------------------------------------\\n\")\n",
    "    \n",
    "#     # Find features with missing values\n",
    "#     if (True in pd.isnull(uniq)):\n",
    "#         s = \"{} has {} missing\" .format(column, pd.isnull(df[column]).sum())\n",
    "#         missing_values.append(s)\n",
    "    \n",
    "#     # Find features with non-numeric values\n",
    "#     for i in range (1, np.prod(uniq.shape)):\n",
    "#         if (re.match('nan', str(uniq[i]))):\n",
    "#             break\n",
    "#         if not (re.search('(^\\d+\\.?\\d*$)|(^\\d*\\.?\\d+$)', str(uniq[i]))):\n",
    "#             nonumeric_values.append(column)\n",
    "#             break\n",
    "  \n",
    "# print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "# print (\"Features with missing values:\\n{}\\n\\n\" .format(missing_values))\n",
    "# print (\"Features with non-numeric values:\\n{}\" .format(nonumeric_values))\n",
    "# print (\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26 in the Republic of Ireland and 6 in Northern Ireland .\n",
    "This project is about Republic of Ireland\n",
    "##### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.ireland.com/en-us/about-ireland/discover-ireland/ireland-counties-and-provinces/\n",
    "df['Provinces'] = ['Leinster',\n",
    "'Ulster',\n",
    "'Munster',\n",
    "'Munster',\n",
    "'Ulster',\n",
    "'Leinster',\n",
    "'Connacht',\n",
    "'Munster',\n",
    "'Leinster',\n",
    "'Leinster',\n",
    "'Leinster',\n",
    "'Connacht',\n",
    "'Munster',\n",
    "'Leinster',\n",
    "'Leinster',\n",
    "'Connacht',\n",
    "'Leinster',\n",
    "'Ulster',\n",
    "'Leinster',\n",
    "'Connacht',\n",
    "'Connacht',\n",
    "'Munster',\n",
    "'Munster',\n",
    "'Leinster',\n",
    "'Leinster',\n",
    "'Leinster',\n",
    "'Ireland']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['County','Provinces']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the last row  that is the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.head(26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create new features using the difference between yearly and 5 yearly data from census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mortgage Count\n",
    "df['diff_mortgage_count_1'] = df['2012_Mortgate_Count'] - df['2011_Mortgate_Count']\n",
    "df['diff_mortgage_count_2'] = df['2013_Mortgate_Count'] - df['2012_Mortgate_Count']\n",
    "df['diff_mortgage_count_3'] = df['2014_Mortgate_Count'] - df['2013_Mortgate_Count']\n",
    "df['diff_mortgage_count_4'] = df['2015_Mortgate_Count'] - df['2014_Mortgate_Count']\n",
    "df['diff_mortgage_count_5'] = df['2016_Countof_mortgages'] - df['2015_Mortgate_Count'] # Different column name\n",
    "df['diff_mortgage_count_6'] = df['2017_Mortgate_Count'] - df['2016_Countof_mortgages']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#New House Prices\n",
    "df['diff_new_house_price_1'] = df['2012_New_House_Price'] - df['2011_New_House_Price']\n",
    "df['diff_new_house_price_2'] = df['2013_New_House_Price'] - df['2012_New_House_Price']\n",
    "df['diff_new_house_price_3'] = df['2014_New_House_Price'] - df['2013_New_House_Price']\n",
    "df['diff_new_house_price_4'] = df['2015_New_House_Price'] - df['2014_New_House_Price']\n",
    "df['diff_new_house_price_5'] = df['2016_New_House_Price '] - df['2015_New_House_Price'] # Extra space in the column name\n",
    "df['diff_new_house_price_6'] = df['2017_New_House_Price'] - df['2016_New_House_Price ']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Second House Prices\n",
    "df['diff_secondhand_house_price_1'] = df['2012_Second_Hand_Price'] - df['2011_Second_Hand_Price']\n",
    "df['diff_secondhand_house_price_2'] = df['2013_Second_Hand_Price'] - df['2012_Second_Hand_Price']\n",
    "df['diff_secondhand_house_price_3'] = df['2014_Second_Hand_Price'] - df['2013_Second_Hand_Price']\n",
    "df['diff_secondhand_house_price_4'] = df['2015_Second_Hand_Price'] - df['2014_Second_Hand_Price']\n",
    "df['diff_secondhand_house_price_5'] = df['2016_Second_Hand_Price'] - df['2015_Second_Hand_Price']\n",
    "df['diff_secondhand_house_price_6'] = df['2017_Second_Hand_Price'] - df['2016_Second_Hand_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sum House Prices\n",
    "df['diff_sum_house_price_1'] = df['2012_Sum_of_Price'] - df['2011_Sum_of_Price']\n",
    "df['diff_sum_house_price_2'] = df['2013_Sum_of_Price'] - df['2012_Sum_of_Price']\n",
    "df['diff_sum_house_price_3'] = df['2014_Sum_of_Price'] - df['2013_Sum_of_Price']\n",
    "df['diff_sum_house_price_4'] = df['2015_Sum_of_Price'] - df['2014_Sum_of_Price']\n",
    "df['diff_sum_house_price_5'] = df['2016_Sum_of_Price'] - df['2015_Sum_of_Price']\n",
    "df['diff_sum_house_price_6'] = df['2017_Sum_of_Price'] - df['2016_Sum_of_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Average Interest Rate\n",
    "df['diff_interestrate_1'] = df['2012_AVG_Interest_Rate'] - df['2011_AVG_Interest_Rate']\n",
    "df['diff_interestrate_2'] = df['2013_AVG_Interest_Rate'] - df['2012_AVG_Interest_Rate']\n",
    "df['diff_interestrate_3'] = df['2014_AVG_Interest_Rate'] - df['2013_AVG_Interest_Rate']\n",
    "df['diff_interestrate_4'] = df['2015_AVG_Interest_Rate'] - df['2014_AVG_Interest_Rate']\n",
    "df['diff_interestrate_5'] = df['2016_AVG_Interest_Rate'] - df['2015_AVG_Interest_Rate']\n",
    "df['diff_interestrate_6'] = df['2017_AVG_Interest_Rate'] - df['2016_AVG_Interest_Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loan Arrears\n",
    "df['diff_loanarrears_1'] = df['2012_LA_Arrears'] - df['2011_LA_Arrears']\n",
    "df['diff_loanarrears_2'] = df['2013_LA_Arrears'] - df['2012_LA_Arrears']\n",
    "df['diff_loanarrears_3'] = df['2014_LA_Arrears'] - df['2013_LA_Arrears']\n",
    "df['diff_loanarrears_4'] = df['2015_LA_Arrears'] - df['2014_LA_Arrears']\n",
    "df['diff_loanarrears_5'] = df['2016_LA_Arrears'] - df['2015_LA_Arrears']\n",
    "df['diff_loanarrears_6'] = df['2017_LA_Arrears'] - df['2016_LA_Arrears']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loans Approved\n",
    "df['diff_loanapproved_1'] = df['2012_Loans Approved'] - df['2011_Loans Approved']\n",
    "df['diff_loanapproved_2'] = df['2013_Loans Approved'] - df['2012_Loans Approved']\n",
    "df['diff_loanapproved_3'] = df['2014_Loans Approved'] - df['2013_Loans Approved']\n",
    "df['diff_loanapproved_4'] = df['2015_Loans Approved'] - df['2014_Loans Approved']\n",
    "df['diff_loanapproved_5'] = df['2016_Loans_Approved'] - df['2015_Loans Approved']\n",
    "df['diff_loanapproved_6'] = df['2017_Loans Approved'] - df['2016_Loans_Approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loans Paid\n",
    "df['diff_loanpaid_1'] = df['2012_Loans_Paid'] - df['2011_Loans_Paid']\n",
    "df['diff_loanpaid_2'] = df['2013_Loans_Paid'] - df['2012_Loans_Paid']\n",
    "df['diff_loanpaid_3'] = df['2014_Loans_Paid'] - df['2013_Loans_Paid']\n",
    "df['diff_loanpaid_4'] = df['2015_Loans_Paid'] - df['2014_Loans_Paid']\n",
    "df['diff_loanpaid_5'] = df['2016_Loans_Paid'] - df['2015_Loans_Paid']\n",
    "df['diff_loanpaid_6'] = df['2017_Loans_Paid'] - df['2016_Loans_Paid']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Diversity in county according to Sex. Take a difference between the 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df['2011_diversity_bothsexes'] = df[['2011_African-Both sexes',\n",
    "'2011_All nationalities-Both sexes',\n",
    "'2011_American (US)-Both sexes', \n",
    " '2011_Brazilian-Both sexes',\n",
    " '2011_French-Both sexes',\n",
    " '2011_German-Both sexes',\n",
    " '2011_Indian-Both sexes',\n",
    " '2011_Irish-Both sexes', \n",
    " '2011_Italian-Both sexes',\n",
    " '2011_Latvian-Both sexes',\n",
    " '2011_Lithuanian-Both sexes', \n",
    " '2011_Not stated, including no nationality-Both sexes', \n",
    " '2011_Other American-Both sexes', \n",
    " '2011_Other Asian-Both sexes', \n",
    " '2011_Other EU28-Both sexes', \n",
    " '2011_Other European-Both sexes',\n",
    " '2011_Other nationalities-Both sexes',\n",
    " '2011_Polish-Both sexes', \n",
    " '2011_Romanian-Both sexes', \n",
    " '2011_Spanish-Both sexes', \n",
    " '2011_UK-Both sexes']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df['2016_diversity_bothsexes'] = df[['2016_African-Both sexes',\n",
    "'2016_All nationalities-Both sexes',\n",
    "'2016_American (US)-Both sexes', \n",
    " '2016_Brazilian-Both sexes',\n",
    " '2016_French-Both sexes',\n",
    " '2016_German-Both sexes',\n",
    " '2016_Indian-Both sexes',\n",
    " '2016_Irish-Both sexes', \n",
    " '2016_Italian-Both sexes',\n",
    " '2016_Latvian-Both sexes',\n",
    " '2016_Lithuanian-Both sexes', \n",
    " '2016_Not stated, including no nationality-Both sexes', \n",
    " '2016_Other American-Both sexes', \n",
    " '2016_Other Asian-Both sexes', \n",
    " '2016_Other EU28-Both sexes', \n",
    " '2016_Other European-Both sexes',\n",
    " '2016_Other nationalities-Both sexes',\n",
    " '2016_Polish-Both sexes', \n",
    " '2016_Romanian-Both sexes', \n",
    " '2016_Spanish-Both sexes', \n",
    " '2016_UK-Both sexes']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff_diversity_bothsexes'] = df['2016_diversity_bothsexes'] - df['2011_diversity_bothsexes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df['diff_diversity_bothsexes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['2011_diversity_female'] = df[['2011_African-Female',\n",
    "'2011_All nationalities-Female',\n",
    "'2011_American (US)-Female',\n",
    "'2011_Brazilian-Female',\n",
    "'2011_French-Female',\n",
    "'2011_German-Female',\n",
    " '2011_Indian-Female',\n",
    "'2011_Irish-Female',\n",
    " '2011_Italian-Female',\n",
    " '2011_Latvian-Female',\n",
    "'2011_Lithuanian-Female',\n",
    "'2011_Not stated, including no nationality-Female',\n",
    "'2011_Other American-Female',\n",
    " '2011_Other Asian-Female',\n",
    "'2011_Other EU28-Female',\n",
    " '2011_Other European-Female',\n",
    "'2011_Other nationalities-Female',\n",
    "'2011_Polish-Female',\n",
    "'2011_Romanian-Female',\n",
    "'2011_Spanish-Female',\n",
    " '2011_UK-Female']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['2016_diversity_female'] = df[['2016_African-Female',\n",
    "'2016_All nationalities-Female',\n",
    "'2016_American (US)-Female',\n",
    "'2016_Brazilian-Female',\n",
    "'2016_French-Female',\n",
    "'2016_German-Female',\n",
    " '2016_Indian-Female',\n",
    "'2016_Irish-Female',\n",
    " '2016_Italian-Female',\n",
    " '2016_Latvian-Female',\n",
    "'2016_Lithuanian-Female',\n",
    "'2016_Not stated, including no nationality-Female',\n",
    "'2016_Other American-Female',\n",
    " '2016_Other Asian-Female',\n",
    "'2016_Other EU28-Female',\n",
    " '2016_Other European-Female',\n",
    "'2016_Other nationalities-Female',\n",
    "'2016_Polish-Female',\n",
    "'2016_Romanian-Female',\n",
    "'2016_Spanish-Female',\n",
    " '2016_UK-Female']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff_diversity_female'] = df['2016_diversity_female'] - df['2011_diversity_female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['2011_diversity_male'] = df[[ '2011_African-Male',\n",
    "'2011_All nationalities-Male',\n",
    " '2011_American (US)-Male',\n",
    " '2011_Brazilian-Male',\n",
    "  '2011_French-Male',\n",
    " '2011_German-Male',\n",
    " '2011_Indian-Male',\n",
    "'2011_Irish-Male',\n",
    " '2011_Italian-Male',\n",
    " '2011_Latvian-Male',\n",
    " '2011_Lithuanian-Male',\n",
    " '2011_Not stated, including no nationality-Male',\n",
    "'2011_Other American-Male',\n",
    "'2011_Other Asian-Male',\n",
    "'2011_Other EU28-Male',\n",
    " '2011_Other European-Male',\n",
    " '2011_Other nationalities-Male',\n",
    "'2011_Polish-Male',\n",
    "'2011_Romanian-Male',\n",
    "'2011_Spanish-Male',\n",
    " '2011_UK-Male']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['2016_diversity_male'] = df[[ '2016_African-Male',\n",
    "'2016_All nationalities-Male',\n",
    " '2016_American (US)-Male',\n",
    " '2016_Brazilian-Male',\n",
    "  '2016_French-Male',\n",
    " '2016_German-Male',\n",
    " '2016_Indian-Male',\n",
    "'2016_Irish-Male',\n",
    " '2016_Italian-Male',\n",
    " '2016_Latvian-Male',\n",
    " '2016_Lithuanian-Male',\n",
    " '2016_Not stated, including no nationality-Male',\n",
    "'2016_Other American-Male',\n",
    "'2016_Other Asian-Male',\n",
    "'2016_Other EU28-Male',\n",
    " '2016_Other European-Male',\n",
    " '2016_Other nationalities-Male',\n",
    "'2016_Polish-Male',\n",
    "'2016_Romanian-Male',\n",
    "'2016_Spanish-Male',\n",
    " '2016_UK-Male']].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff_diversity_male'] = df['2016_diversity_male'] - df['2011_diversity_male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff_male_population'] = df['2016_Male_Population'] - df['2011_Male_Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff_female_population'] = df['2016_Female_Population'] - df['2011_Female_Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff_total_population'] = df['2016_Total_Population'] - df['2011_Total_Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff_migration_population'] = df['2016_Migration_Population'] - df['2011_Migration_Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff_1-14years_population'] = df['2016_1 - 14 years'] -df['2011_1 - 14 years']\n",
    "df['diff_15-19years_population'] = df['2016_15 - 19 years'] -df['2011_15 - 19 years']\n",
    "df['diff_20-24years_population'] = df['2016_20 - 24 years'] -df['2011_20 - 24 years']\n",
    "df['diff_25-29years_population'] = df['2016_25 - 29 years'] -df['2011_25 - 29 years']\n",
    "df['diff_30-34years_population'] = df['2016_30 - 34 years'] -df['2011_30 - 34 years']\n",
    "df['diff_35-44years_population'] = df['2016_35 - 44 years'] -df['2011_35 - 44 years']\n",
    "df['diff_45-54years_population'] = df['2016_45 - 54 years'] -df['2011_45 - 54 years']\n",
    "df['diff_55-64years_population'] = df['2016_55 - 64 years'] -df['2011_55 - 64 years']\n",
    "df['diff_65-74years_population'] = df['2016_65 - 74 years'] -df['2011_65 - 74 years']\n",
    "df['diff_75years_over_population'] = df['2016_75 years and over'] -df['2011_75 years and over']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Employment\n",
    "df['diff_employment'] = df['2016_employment'] - df['2011_employment']\n",
    "df['diff_average'] = df['Average of 2016'] - df['Average of 2011']\n",
    "df['diff_All persons aged 15 years and over'] = df['2016_All persons aged 15 years and over'] - df['2011_All persons aged 15 years and over']\n",
    "df['diff_Employer or own account worker'] = df['2016_Employer or own account worker'] - df['2011_Employer or own account worker']\n",
    "df['diff_Employee'] = df['2016_Employee'] - df['2011_Employee']\n",
    "df['diff_Assisting_relative'] = df['2016_Assisting_relative'] - df['2011_Assisting_relative']\n",
    "df['diff_Unemployed looking for first regular job'] = df['2016_Unemployed looking for first regular job'] - df['2011_Unemployed looking for first regular job']\n",
    "df['diff_Unemployed having lost or given up previous job'] = df['2016_Unemployed having lost or given up previous job'] - df['2011_Unemployed having lost or given up previous job']\n",
    "df['diff_Student'] = df['2016_Student'] - df['2011_Student']\n",
    "df['diff_Looking after home/family'] = df['2016_Looking after home/family'] - df['2011_Looking after home/family']\n",
    "df['diff_Retired'] = df['2016_Retired'] - df['2011_Retired']\n",
    "df['diff_Unable to work due to permanent sickness or disability'] = df['2016_Unable to work due to permanent sickness or disability'] - df['2011_Unable to work due to permanent sickness or disability']\n",
    "df['diff_Other economic status'] = df['2016_Other economic status'] - df['2011_Other economic status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#martital Status\n",
    "df['diff_Married_First_Marriage'] = df['2016_Married_First_Marriage'] - df['2011_Married_First_Marriage']\n",
    "df['diff_divorced'] = df['2016_Divorsed'] - df['2011_Divorsed']\n",
    "df['diff_Same_Sex_Civil Partners'] = df['2016_Same_Sex_Civil Partners'] - df['2011_Same_Sex_Civil Partners']\n",
    "df['diff_Remarried'] = df['2016_Remarried'] - df['2011_Remarried']\n",
    "df['diff_Seperated'] = df['2016_Seperated'] - df['2011_Seperated']\n",
    "df['diff_Single'] = df['2016_Single'] - df['2011_Single']\n",
    "df['diff_Widowed'] = df['2016_Widowed'] - df['2011_Widowed']\n",
    "df['diff_Remarried'] = df['2016_Remarried'] - df['2011_Remarried']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Commmuter Information\n",
    "df['diff_all_depature_timeAll_Persons'] = df['2016_all_depature_timeAll_Persons'] - df['2011_all_depature_timeAll_Persons']\n",
    "df['diff_all_depature_time_Children at school aged between 5 and 12 years'] = df['2016_all_depature_time_Children at school aged between 5 and 12 years'] - df['2011_all_depature_time_Children at school aged between 5 and 12 years']\n",
    "df['diff_all_depature_time_Students at school or college aged between 13 and 18 years'] = df['2016_all_depature_time_Students at school or college aged between 13 and 18 years'] - df['2011_all_depature_time_Students at school or college aged between 13 and 18 years']\n",
    "df['diff_all_depature_time_Students at school or college aged 19 years and over'] = df['2016_all_depature_time_Students at school or college aged 19 years and over'] - df['2011_all_depature_time_Students at school or college aged 19 years and over']\n",
    "df['diff_all_depature_time_Population aged 15 years and over at work'] = df['2016_all_depature_time_Population aged 15 years and over at work'] - df['2011_all_depature_time_Population aged 15 years and over at work']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Type of house\n",
    "df['diff_AllPrivate'] = df['2016_AllPrivate'] - df['2011_AllPrivate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df[['County',\n",
    "'diff_mortgage_count_1',\n",
    " 'diff_mortgage_count_2',\n",
    " 'diff_mortgage_count_3',\n",
    " 'diff_mortgage_count_4',\n",
    " 'diff_mortgage_count_5',\n",
    " 'diff_mortgage_count_6',\n",
    " 'diff_new_house_price_1',\n",
    " 'diff_new_house_price_2',\n",
    " 'diff_new_house_price_3',\n",
    " 'diff_new_house_price_4',\n",
    " 'diff_new_house_price_5',\n",
    " 'diff_new_house_price_6',\n",
    " 'diff_secondhand_house_price_1',\n",
    " 'diff_secondhand_house_price_2',\n",
    " 'diff_secondhand_house_price_3',\n",
    " 'diff_secondhand_house_price_4',\n",
    " 'diff_secondhand_house_price_5',\n",
    " 'diff_secondhand_house_price_6',\n",
    " 'diff_sum_house_price_1',\n",
    " 'diff_sum_house_price_2',\n",
    " 'diff_sum_house_price_3',\n",
    " 'diff_sum_house_price_4',\n",
    " 'diff_sum_house_price_5',\n",
    " 'diff_sum_house_price_6',\n",
    " 'diff_interestrate_1',\n",
    " 'diff_interestrate_2',\n",
    " 'diff_interestrate_3',\n",
    " 'diff_interestrate_4',\n",
    " 'diff_interestrate_5',\n",
    " 'diff_interestrate_6',\n",
    " 'diff_loanarrears_1',\n",
    " 'diff_loanarrears_2',\n",
    " 'diff_loanarrears_3',\n",
    " 'diff_loanarrears_4',\n",
    " 'diff_loanarrears_5',\n",
    " 'diff_loanarrears_6',\n",
    " 'diff_loanapproved_1',\n",
    " 'diff_loanapproved_2',\n",
    " 'diff_loanapproved_3',\n",
    " 'diff_loanapproved_4',\n",
    " 'diff_loanapproved_5',\n",
    " 'diff_loanapproved_6',\n",
    " 'diff_loanpaid_1',\n",
    " 'diff_loanpaid_2',\n",
    " 'diff_loanpaid_3',\n",
    " 'diff_loanpaid_4',\n",
    " 'diff_loanpaid_5',\n",
    " 'diff_loanpaid_6',\n",
    "   'diff_diversity_bothsexes',\n",
    "   'diff_diversity_female','diff_diversity_male',\n",
    " 'diff_male_population',\n",
    " 'diff_female_population',\n",
    " 'diff_total_population',\n",
    " 'diff_migration_population',\n",
    " 'diff_1-14years_population',\n",
    " 'diff_15-19years_population',\n",
    " 'diff_20-24years_population',\n",
    " 'diff_25-29years_population',\n",
    " 'diff_30-34years_population',\n",
    " 'diff_35-44years_population',\n",
    " 'diff_45-54years_population',\n",
    " 'diff_55-64years_population',\n",
    " 'diff_65-74years_population',\n",
    " 'diff_75years_over_population',\n",
    " 'diff_employment',\n",
    " 'diff_average',\n",
    " 'diff_Married_First_Marriage',\n",
    " 'diff_divorced',\n",
    " 'diff_Same_Sex_Civil Partners',\n",
    " 'diff_Remarried',\n",
    " 'diff_Seperated',\n",
    " 'diff_Single',\n",
    " 'diff_Widowed',\n",
    "   'diff_AllPrivate',\n",
    " 'diff_All persons aged 15 years and over',\n",
    " 'diff_Employer or own account worker',\n",
    " 'diff_Employee',\n",
    " 'diff_Assisting_relative',\n",
    " 'diff_Unemployed looking for first regular job',\n",
    " 'diff_Unemployed having lost or given up previous job',\n",
    " 'diff_Student',\n",
    " 'diff_Looking after home/family',\n",
    " 'diff_Retired',\n",
    " 'diff_Unable to work due to permanent sickness or disability',\n",
    " 'diff_Other economic status',\n",
    " 'diff_all_depature_timeAll_Persons',\n",
    " 'diff_all_depature_time_Children at school aged between 5 and 12 years',\n",
    " 'diff_all_depature_time_Students at school or college aged between 13 and 18 years',\n",
    " 'diff_all_depature_time_Students at school or college aged 19 years and over',\n",
    " 'diff_all_depature_time_Population aged 15 years and over at work',\n",
    "   #Loans Approved\n",
    "\n",
    " '2011_Loans Approved',\n",
    " '2012_Loans Approved',\n",
    " '2013_Loans Approved',\n",
    " '2014_Loans Approved',\n",
    " '2015_Loans Approved', \n",
    "'2016_Loans_Approved',#\n",
    " '2017_Loans Approved',\n",
    "\n",
    "#Loans Paid\n",
    "'2011_Loans_Paid',\n",
    "'2012_Loans_Paid',\n",
    "'2013_Loans_Paid',\n",
    " '2014_Loans_Paid',\n",
    "'2015_Loans_Paid',\n",
    " '2017_Loans_Paid', \n",
    " '2016_Loans_Paid',\n",
    "\n",
    "# Repossesions of the houses\n",
    "\n",
    "'2011_Forced',\n",
    " '2011_Voluntary',\n",
    " '2012_Forced',\n",
    " '2012_Voluntary',\n",
    " '2013_Forced',\n",
    " '2013_Voluntary',\n",
    " '2014_Forced',\n",
    " '2014_Voluntary',\n",
    " '2015_Forced',\n",
    " '2015_Voluntary',\n",
    " '2016_Forced',\n",
    " '2017_Voluntary',\n",
    " '2017_Forced',#May be remove this\n",
    " '2017_Voluntary.1',#Remove this\n",
    "\n",
    "#Number of Employees\n",
    " '2012_Employees',\n",
    " '2013_Employees',\n",
    " '2014_Employees',\n",
    " '2015_Employees',\n",
    " '2016_Employees',\n",
    "\n",
    "#Arrears—\n",
    "'2011_LA_Arrears',\n",
    "'2012_LA_Arrears',\n",
    " '2013_LA_Arrears',\n",
    "'2014_LA_Arrears',\n",
    "'2015_LA_Arrears',\n",
    " '2016_LA_Arrears',\n",
    "'2017_LA_Arrears',\n",
    "# Target Label\n",
    "'Provinces'\n",
    "           ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def describe_dataframe(df=pd.DataFrame()):\n",
    "    \"\"\"This function generates descriptive stats of a dataframe\n",
    "    Args:\n",
    "        df (dataframe): the dataframe to be analyzed\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\"*30)\n",
    "    print(\"About the Data\")\n",
    "    print(\"*\"*30)\n",
    "    \n",
    "    print(\"Number of rows::\",df.shape[0])\n",
    "    print(\"Number of columns::\",df.shape[1])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Column Names::\",df.columns.values.tolist())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Column Data Types::\\n\",df.dtypes)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Columns with Missing Values::\",df.columns[df.isnull().any()].tolist())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Number of rows with Missing Values::\",len(pd.isnull(df).any(1).nonzero()[0].tolist()))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Sample Indices with missing data::\",pd.isnull(df).any(1).nonzero()[0].tolist()[0:5])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"General Stats::\")\n",
    "    print(df.info())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Summary Stats::\")\n",
    "    print(df.describe())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Dataframe Sample Rows::\")\n",
    "    display(df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe_dataframe(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['2012_Employees'] = train['2012_Employees'].apply(lambda x: float(x.replace(',', '')))\n",
    "train['2013_Employees'] = train['2013_Employees'].apply(lambda x: float(x.replace(',', '')))\n",
    "train['2014_Employees'] = train['2014_Employees'].apply(lambda x: float(x.replace(',', '')))\n",
    "train['2015_Employees'] = train['2015_Employees'].apply(lambda x: float(x.replace(',', '')))\n",
    "train['2016_Employees'] = train['2016_Employees'].apply(lambda x: float(x.replace(',', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove county and the target label\n",
    "#X = features.drop('delinquent', axis=1)\n",
    "X = train[train.columns.difference(['County','Provinces'])]\n",
    "y = train['Provinces']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing features with low variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "threshold = 0.90\n",
    "vt = VarianceThreshold().fit(X)\n",
    "\n",
    "# Find feature names\n",
    "feat_var_threshold = X.columns[vt.variances_ > threshold * (1-threshold)]\n",
    "feat_var_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'variance': vt.variances_,\n",
    "              'select_feature': vt.get_support()},\n",
    "            index=X.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Top 15 most important features\n",
    "#According to RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance_scores = model.feature_importances_\n",
    "feature_importances = [(feature, score) for feature, score in zip(X.columns, importance_scores)]\n",
    "sorted(feature_importances, key=lambda x: -x[1])[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rfe = RFE(estimator=lr, n_features_to_select=15, step=1)\n",
    "rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select_features_rfe = rfe.get_support()\n",
    "feature_names_rfe = X.columns[select_features_rfe]\n",
    "print(feature_names_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set of the Select Kbest and RFE\n",
    "set(feat_var_threshold) & set(feature_names_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select a subset of X after feature selection\n",
    "X = X[['2013_LA_Arrears',\n",
    " '2015_Loans Approved',\n",
    " 'diff_loanarrears_1',\n",
    " 'diff_loanarrears_4',\n",
    " 'diff_new_house_price_1',\n",
    " 'diff_new_house_price_3',\n",
    " 'diff_new_house_price_4',\n",
    " 'diff_new_house_price_5',\n",
    " 'diff_new_house_price_6',\n",
    " 'diff_secondhand_house_price_1',\n",
    " 'diff_secondhand_house_price_4',\n",
    " 'diff_secondhand_house_price_5',\n",
    " 'diff_sum_house_price_1',\n",
    " 'diff_sum_house_price_2',\n",
    " 'diff_sum_house_price_5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing the table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Standard Scalar\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import model_selection\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# test_size = 0.33\n",
    "# seed = 7\n",
    "# X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "# result = model.score(X_test, y_test)\n",
    "# print(\"Accuracy: %.3f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#leave one out cross validation for linear regression\n",
    "#https://www.ritchieng.com/machine-learning-cross-validation/\n",
    "#https://machinelearningmastery.com/evaluate-performance-machine-learning-algorithms-python-using-resampling/\n",
    "from sklearn import model_selection\n",
    "num_folds = 10\n",
    "num_instances = len(X)\n",
    "loocv = model_selection.LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "results = model_selection.cross_val_score(model, X, y, cv=loocv)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score, roc_auc_score\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('K-NN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVC', SVC(probability=True)))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "models.append(('ADA', AdaBoostClassifier()))\n",
    "models.append(('GBC', GradientBoostingClassifier()))\n",
    "models.append(('MLP', MLPClassifier()))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "accuracy = []\n",
    "names = []\n",
    "std =[]\n",
    "#loocv = model_selection.LeaveOneOut()\n",
    "\n",
    "for name, model in models:\n",
    "    results = model_selection.cross_val_score(model, X, y, cv=loocv)\n",
    "    accuracy.append(results.mean()*100.0)\n",
    "    std.append(results.std()*100.0)\n",
    "    #roc.append(roc_auc_score(y_test, predictions))\n",
    "    \n",
    "    names.append(name)\n",
    "for name, acc,s in zip(names, accuracy,std):\n",
    "    #Accuracy mean and standard deviation\n",
    "    print(\"Model: {0:10s} : Accuracy: {1:4.3f}% | ({2:4.3f}%)\".format(name,acc,s))\n",
    "    ## boxplot algorithm comparison\n",
    "plt.style.use('fivethirtyeight')\n",
    "fig = plt.figure(figsize=(4, 3), dpi=80, facecolor='w', edgecolor='k')\n",
    "fig.suptitle('Algorithm Comparison',fontsize=16)\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(accuracy)\n",
    "ax.set_xticklabels(names)\n",
    "plt.ylabel('Mean', fontsize=12)\n",
    "plt.xlabel('Algorithm', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/\n",
    "\n",
    "https://medium.com/@elutins/grid-searching-in-machine-learning-quick-explanation-and-python-implementation-550552200596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = DecisionTreeClassifier()\n",
    "criterion =['gini','entropy']\n",
    "max_depth =[1,3,5,None]\n",
    "splitter =['best','random']\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(criterion = criterion,max_depth = max_depth,splitter=splitter))\n",
    "grid.fit(X,y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_rand\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'max_depth': sp_rand()}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = DecisionTreeClassifier()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100)\n",
    "rsearch.fit(X,y)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
